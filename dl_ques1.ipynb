{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dl_ques1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1RmV946mzqfhXfTCvXnJUqsmu81eodiQO","authorship_tag":"ABX9TyPZXCDw14lpkmboPP8sjcWX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"o7liVZ3dltrr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f792ff1a-b902-4728-bd66-ea63f858cbba","executionInfo":{"status":"ok","timestamp":1584737006321,"user_tz":300,"elapsed":4242,"user":{"displayName":"tejaswini rayapati","photoUrl":"","userId":"05015603313691621650"}}},"source":["import pandas\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","\n","# load dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","dataset = pd.read_csv(\"diabetes.csv\", header=None).values\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n","                                                    test_size=0.25, random_state=87)\n","np.random.seed(155)\n","my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(30, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(30, activation='relu'))\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n","                                     initial_epoch=0)\n","print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","576/576 [==============================] - 1s 947us/step - loss: 3.2721 - acc: 0.4861\n","Epoch 2/100\n","576/576 [==============================] - 0s 43us/step - loss: 1.2576 - acc: 0.5295\n","Epoch 3/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.9282 - acc: 0.5990\n","Epoch 4/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.7816 - acc: 0.6562\n","Epoch 5/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.7230 - acc: 0.6580\n","Epoch 6/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.7055 - acc: 0.6649\n","Epoch 7/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.6680 - acc: 0.6806\n","Epoch 8/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.6540 - acc: 0.6753\n","Epoch 9/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.6453 - acc: 0.6823\n","Epoch 10/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.6297 - acc: 0.6736\n","Epoch 11/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.6085 - acc: 0.7031\n","Epoch 12/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5859 - acc: 0.7014\n","Epoch 13/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5872 - acc: 0.7205\n","Epoch 14/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5991 - acc: 0.6910\n","Epoch 15/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5799 - acc: 0.7170\n","Epoch 16/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5936 - acc: 0.6927\n","Epoch 17/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5451 - acc: 0.7326\n","Epoch 18/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5515 - acc: 0.7170\n","Epoch 19/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5627 - acc: 0.7031\n","Epoch 20/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5485 - acc: 0.7222\n","Epoch 21/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5478 - acc: 0.7240\n","Epoch 22/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5585 - acc: 0.7222\n","Epoch 23/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5298 - acc: 0.7535\n","Epoch 24/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.6158 - acc: 0.6806\n","Epoch 25/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5728 - acc: 0.7274\n","Epoch 26/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5675 - acc: 0.7431\n","Epoch 27/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5331 - acc: 0.7431\n","Epoch 28/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5620 - acc: 0.7205\n","Epoch 29/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5768 - acc: 0.7222\n","Epoch 30/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5832 - acc: 0.7257\n","Epoch 31/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.6022 - acc: 0.6615\n","Epoch 32/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5433 - acc: 0.7274\n","Epoch 33/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5306 - acc: 0.7344\n","Epoch 34/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5294 - acc: 0.7292\n","Epoch 35/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5455 - acc: 0.7274\n","Epoch 36/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5325 - acc: 0.7326\n","Epoch 37/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.5402 - acc: 0.7396\n","Epoch 38/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5306 - acc: 0.7274\n","Epoch 39/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5379 - acc: 0.7378\n","Epoch 40/100\n","576/576 [==============================] - 0s 57us/step - loss: 0.5399 - acc: 0.7552\n","Epoch 41/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5295 - acc: 0.7378\n","Epoch 42/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5495 - acc: 0.7292\n","Epoch 43/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5439 - acc: 0.7240\n","Epoch 44/100\n","576/576 [==============================] - 0s 54us/step - loss: 0.5555 - acc: 0.7135\n","Epoch 45/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5472 - acc: 0.7378\n","Epoch 46/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5892 - acc: 0.7135\n","Epoch 47/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5116 - acc: 0.7622\n","Epoch 48/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5293 - acc: 0.7413\n","Epoch 49/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5276 - acc: 0.7361\n","Epoch 50/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5144 - acc: 0.7431\n","Epoch 51/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5162 - acc: 0.7448\n","Epoch 52/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5166 - acc: 0.7587\n","Epoch 53/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5086 - acc: 0.7413\n","Epoch 54/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5204 - acc: 0.7500\n","Epoch 55/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5199 - acc: 0.7431\n","Epoch 56/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5143 - acc: 0.7483\n","Epoch 57/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5536 - acc: 0.7344\n","Epoch 58/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.6010 - acc: 0.7083\n","Epoch 59/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5424 - acc: 0.7257\n","Epoch 60/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5196 - acc: 0.7448\n","Epoch 61/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5100 - acc: 0.7465\n","Epoch 62/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5136 - acc: 0.7465\n","Epoch 63/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5027 - acc: 0.7326\n","Epoch 64/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5320 - acc: 0.7344\n","Epoch 65/100\n","576/576 [==============================] - 0s 57us/step - loss: 0.5308 - acc: 0.7483\n","Epoch 66/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5124 - acc: 0.7448\n","Epoch 67/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5219 - acc: 0.7413\n","Epoch 68/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5141 - acc: 0.7483\n","Epoch 69/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5165 - acc: 0.7483\n","Epoch 70/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.4999 - acc: 0.7569\n","Epoch 71/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5136 - acc: 0.7448\n","Epoch 72/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5132 - acc: 0.7483\n","Epoch 73/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5170 - acc: 0.7622\n","Epoch 74/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5579 - acc: 0.7465\n","Epoch 75/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.4916 - acc: 0.7552\n","Epoch 76/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.4911 - acc: 0.7552\n","Epoch 77/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5212 - acc: 0.7448\n","Epoch 78/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5337 - acc: 0.7309\n","Epoch 79/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5600 - acc: 0.7222\n","Epoch 80/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.4978 - acc: 0.7569\n","Epoch 81/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.4962 - acc: 0.7622\n","Epoch 82/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5030 - acc: 0.7483\n","Epoch 83/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5026 - acc: 0.7500\n","Epoch 84/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.4917 - acc: 0.7656\n","Epoch 85/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.4859 - acc: 0.7569\n","Epoch 86/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.4950 - acc: 0.7535\n","Epoch 87/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5181 - acc: 0.7569\n","Epoch 88/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5019 - acc: 0.7622\n","Epoch 89/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.4916 - acc: 0.7691\n","Epoch 90/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.4878 - acc: 0.7743\n","Epoch 91/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.4879 - acc: 0.7708\n","Epoch 92/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.4998 - acc: 0.7431\n","Epoch 93/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.4842 - acc: 0.7760\n","Epoch 94/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.4856 - acc: 0.7552\n","Epoch 95/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.4823 - acc: 0.7830\n","Epoch 96/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.4916 - acc: 0.7431\n","Epoch 97/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5079 - acc: 0.7587\n","Epoch 98/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.4885 - acc: 0.7691\n","Epoch 99/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.4710 - acc: 0.7917\n","Epoch 100/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.4790 - acc: 0.7674\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_15 (Dense)             (None, 30)                270       \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 30)                930       \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 1)                 31        \n","=================================================================\n","Total params: 1,231\n","Trainable params: 1,231\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","192/192 [==============================] - 0s 701us/step\n","[0.5550506065289179, 0.7239583333333334]\n"],"name":"stdout"}]}]}